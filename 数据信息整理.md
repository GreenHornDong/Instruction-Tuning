1、blip_laion_cc_sbu_558k：所有指令均围绕描述一下这张图的内容构造, 指令过于简单，单轮对话，信息量极少。

<br />![图片](https://github.com/GreenHornDong/Instruction-Tuning/assets/101792419/24e656d8-ac8c-4993-b070-692a953870a7)

2、llava_v1_5_mix665k：多轮对话指令，主要围绕图的内容展开多轮对话，包括图中物体的颜色，位置，以及更困难的图片理解，最后还包括纯文本的问题，多种语言数据。

<br /><img width="922" alt="image" src="https://github.com/GreenHornDong/Instruction-Tuning/assets/101792419/b12e6b3a-2c34-49e8-8d9b-899d1c1d50dc">

3、sharegpt4v_mix665k_cap23k_coco-ap9k_lcs3k_sam9k_div2k：如原文所说，将llava_v1_5_mix665k中的少量数据进行替换，将其中一些多轮对话换成由GPT-4V生成的高质量描述（此为单轮对话，指令格式为详细说明一下图片内容，数据来源为手动收集的多样化的图片），下图为其中替换的数据格式。

<br /><img width="596" alt="image" src="https://github.com/GreenHornDong/Instruction-Tuning/assets/101792419/7b9dcd99-aa7b-4f35-83cf-9a57da443040">

4、SVIT_mix_665K，由llava_v1_5_mix665k演化而来，将其中的LLaVA-Instruct-150K更换为SVIT core-150K，此数据集由纯文本GPT-4生成，但是不给出提示，全部为zero-shot，确保创造力，图片来源为VG。一共四种数据，包括对话，复杂推理，指代和详细描述。对话中很多都是短对话，要求模型使用一个词语或词组进行回答。

<br /><img width="880" alt="image" src="https://github.com/GreenHornDong/Instruction-Tuning/assets/101792419/a78203e2-5801-49c8-b3f2-bc7e8976f50b">

由此得见，llava_v1_5_mix665K确实是高质量数据，均由其演化而来。

注：上传的excel表格均是原始数据集每隔500条进行一次采样获得。
